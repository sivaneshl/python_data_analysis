
# Part 2 - Topic Modelling
# For the second part of this assignment, you will use Gensim's LDA (Latent Dirichlet Allocation) model to
# model topics in newsgroup_data. You will first need to finish the code in the cell below by using
# gensim.models.ldamodel.LdaModel constructor to estimate LDA model parameters on the corpus, and save to the
# variable ldamodel. Extract 10 topics using corpus and id_map, and with passes=25 and random_state=34.

import pickle
import gensim
from sklearn.feature_extraction.text import CountVectorizer

# Load the list of documents
with open('../resources/newsgroups', 'rb') as f:
    newsgroup_data = pickle.load(f)

# Use CountVectorizor to find three letter tokens, remove stop_words,
# remove tokens that don't appear in at least 20 documents,
# remove tokens that appear in more than 20% of the documents
vect = CountVectorizer(min_df=20, max_df=0.2, stop_words='english',
                       token_pattern='(?u)\\b\\w\\w\\w+\\b')

# Fit and transform
X = vect.fit_transform(newsgroup_data)

# Convert sparse matrix to gensim corpus.
corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)

# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)
id_map = dict((v, k) for k, v in vect.vocabulary_.items())
# print(id_map)

# Use the gensim.models.ldamodel.LdaModel constructor to estimate
# LDA model parameters on the corpus, and save to the variable `ldamodel`

ldamodel = gensim.models.ldamodel.LdaModel(corpus,
                                           id2word=id_map,
                                           num_topics=10,
                                           passes=25,
                                           random_state=34)
# print(ldamodel)

# lda_topics
# Using ldamodel, find a list of the 10 topics and the most significant 10 words in each topic.
# This should be structured as a list of 10 tuples where each tuple takes on the form:
# (9, '0.068*"space" + 0.036*"nasa" + 0.021*"science" + 0.020*"edu" + 0.019*"data" + 0.017*"shuttle" + 0.015*"launch" + 0.015*"available" + 0.014*"center" + 0.014*"sci"')
#
# for example.
#
# This function should return a list of tuples.
def lda_topics():
    topics = ldamodel.print_topics(num_topics=10, num_words=10)
    return topics
# print(lda_topics())

# topic_distribution
# For the new document new_doc, find the topic distribution. Remember to use vect.transform on the the new doc,
# and Sparse2Corpus to convert the sparse matrix to gensim corpus.
# This function should return a list of tuples, where each tuple is (#topic, probability)
new_doc = ["\n\nIt's my understanding that the freezing will start to occur because \
of the\ngrowing distance of Pluto and Charon from the Sun, due to it's\nelliptical orbit. \
It is not due to shadowing effects. \n\n\nPluto can shadow Charon, and vice-versa.\n\nGeorge \
Krumins\n-- "]


def topic_distribution():
    X = vect.transform(new_doc)
    corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)
    topics = ldamodel.get_document_topics(corpus)
    return list(topics)[0]
print(topic_distribution())

# topic_names
# From the list of the following given topics, assign topic names to the topics you found. If none of these
# names best matches the topics you found, create a new 1-3 word "title" for the topic.
# Topics: Health, Science, Automobiles, Politics, Government, Travel, Computers & IT, Sports, Business,
# Society & Lifestyle, Religion, Education.
# This function should return a list of 10 strings
def topic_names():
    topics = ['Health', 'Science', 'Automobiles', 'Government', 'Computers & IT', 'Sports', 'Business',
              'Society & Lifestyle', 'Religion', 'Education']

    return topics
print(topic_names())